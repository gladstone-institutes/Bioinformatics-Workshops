---
title: "Introduction to Machine Learning - Part 1"
subtitle: "Data Exploration & Preprocessing"
author: "Gladstone Bioinformatics Core"
date: "`r Sys.Date()`"
output:
  html_document:
    toc: true
    toc_float: true
    toc_depth: 3
    code_folding: show
    theme: flatly
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introduction

Welcome to the Introduction to Machine Learning workshop! In this first part, we'll explore our dataset and prepare it for machine learning algorithms.

## Why Data Preprocessing Matters

Before applying any machine learning algorithm, it's crucial to understand and prepare your data. Different ML algorithms have different requirements:

- **Missing data**: Most algorithms cannot handle missing values
- **Categorical variables**: May need to be encoded as numbers
- **Feature scaling**: Some algorithms are sensitive to the scale of features

**Key takeaway:** Always clean and preprocess your data before applying ML algorithms!

---

# Load Required Libraries

```{r libraries}
# Data manipulation & visualization (includes ggplot2)
library(tidyverse)
```

---

# Load and Explore the Data

We'll use a COVID-19 symptoms dataset containing patient symptoms and test results.  
- **Target variable**: `covid19_test_results` (what we want to predict)  
- **Features**: All other columns (symptoms and risk factors)

```{r load-explore-data}
# Load the data
covid_data <- read.csv("data/covid-symptoms.csv")

# Check target distribution
print(table(covid_data$covid19_test_results))
```  

---

# Handling Missing Data

Most ML algorithms cannot handle missing values. Two strategies:  
- **Remove rows**: Simple, but may lose data  
- **Impute values**: Replace with column mean, median, or mode  

We'll use **median imputation** for numeric columns:  

```{r imputation}
# Create a copy for imputation
covid_imputed <- covid_data

# Identify numeric columns (excluding target)
numeric_cols <- names(covid_imputed)[sapply(covid_imputed, is.numeric)]

# Impute numeric columns with median
for (col in numeric_cols) {
  if (sum(is.na(covid_imputed[[col]])) > 0) {
    median_val <- median(covid_imputed[[col]], na.rm = TRUE)
    covid_imputed[[col]][is.na(covid_imputed[[col]])] <- median_val
    cat("Imputed", col, "with median:", median_val, "\n")
  }
}

# Check if any missing values remain
cat("Remaining missing values:", sum(is.na(covid_imputed)))
```

---

# Handling Categorical Variables

Different algorithms have different requirements for categorical variables:  
- **K-means, SVM**: Require numeric input → need encoded version  
- **Random Forest**: Can handle categorical variables directly → can use original  

We'll prepare both versions to accommodate different algorithms.

### Handle Missing Values

First, let's handle missing values in the original categorical variable:

```{r handle-categorical-missing}
# Replace missing/empty values with "No cough"
covid_imputed$cough_severity <- ifelse(
  is.na(covid_imputed$cough_severity) | covid_imputed$cough_severity == "",
  "No cough",
  covid_imputed$cough_severity
)

# Convert to factor to ensure proper handling
covid_imputed$cough_severity <- as.factor(covid_imputed$cough_severity)

# Check the distribution
table(covid_imputed$cough_severity)
```

### Create Encoded Version

```{r label-encoding}
# Encode ordinal cough_severity: No cough=0 < Mild=1 < Moderate=2 < Severe=3
# This version will be used for K-means (Part 2)
covid_imputed$cough_severity_encoded <- case_when(
  covid_imputed$cough_severity == "No cough" ~ 0,
  covid_imputed$cough_severity == "Mild" ~ 1,
  covid_imputed$cough_severity == "Moderate" ~ 2,
  covid_imputed$cough_severity == "Severe" ~ 3,
  TRUE ~ 0
)
table(covid_imputed$cough_severity_encoded)
```

**Note:** We keep both `cough_severity` (original categorical) and `cough_severity_encoded` (numeric) in our dataset:  
- **Part 2 (K-means)**: Will use `cough_severity_encoded` (requires numeric input)  
- **Part 3 (Random Forest)**: Will use `cough_severity` (can handle categorical variables directly)  

---

# Feature Scaling

Some algorithms (K-means, SVM, KNN) use distance calculations and are sensitive to feature scales.

```{r scale-demo}
# Compare scales - temperature vs binary symptoms
cat("Temperature range:", range(covid_imputed$temperature, na.rm = TRUE), "\n")
```

If temperature ranges from 36-40 and symptoms are 0-1, temperature will dominate distance calculations!

**Standardization (Z-score):** transforms features to mean=0, sd=1

```{r standardization}
# Example: Standardize temperature: (x - mean) / sd
temperature_scaled <- scale(covid_imputed$temperature)

cat("Original - Mean:", round(mean(covid_imputed$temperature), 2), 
    "SD:", round(sd(covid_imputed$temperature), 2), "\n",
    "Scaled - Mean:", round(mean(temperature_scaled), 4), 
    "SD:", round(sd(temperature_scaled), 4), "\n")
```

**Note:** We demonstrate scaling here, but we'll scale all features together in Part 2 when needed for K-means. Random Forest (Part 3) doesn't require scaling.

---

# Prepare Final Dataset for ML

```{r final-dataset}
# Create the final clean dataset for machine learning
# Note: We include both cough_severity (categorical) and cough_severity_encoded (numeric)
# - K-means (Part 2) will use cough_severity_encoded
# - Random Forest (Part 3) will use cough_severity (can handle categorical variables)
covid_ml <- covid_imputed %>%
  select(
    # Target
    covid19_test_results,
    # Numeric features
    temperature,
    # Binary features
    high_risk_exposure_occupation,
    high_risk_interactions,
    labored_respiration,
    rhonchi,
    cough,
    fever,
    sob,
    diarrhea,
    fatigue,
    headache,
    loss_of_smell,
    loss_of_taste,
    runny_nose,
    muscle_sore,
    sore_throat,
    wheezes,
    # Categorical (for Random Forest)
    cough_severity,
    # Encoded categorical (for K-means)
    cough_severity_encoded
  )

# Final check
cat("Final dataset dimensions:", dim(covid_ml), "\n",
    "Missing values:", sum(is.na(covid_ml)), "\n")
```

```{r save-cleaned-data}
# Save the cleaned dataset for use in subsequent parts
# This file (covid_ml_clean.csv) will be used in:
# - Part 2 (K-means clustering)
# - Part 3 (Random Forest classification)
write.csv(covid_ml, "data/covid_ml_clean.csv", row.names = FALSE)
cat("Cleaned dataset saved to 'data/covid_ml_clean.csv'\n")
cat("This file will be used in Part 2 (K-means) and Part 3 (Random Forest)\n")
```

---

# Summary

In this part, we learned:

1. ✅ **Explore your data** before applying ML algorithms
2. ✅ **Handle missing values** - remove or impute
3. ✅ **Encode categorical variables** - convert to numeric
4. ✅ **Scale features** when using distance-based algorithms (like K-means)

## What's Next?

In the following parts, we'll use this cleaned dataset to:

- **Part 2:** Apply K-means for clustering
- **Part 3:** Apply Random Forest for classification

---

# Session Info

```{r session-info}
sessionInfo()
```